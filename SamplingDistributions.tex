\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Sampling Distributions}
\author{Naveen Thakur }
\date{March 2021}

\begin{document}

\maketitle

\section{Introduction}
A 'sample statistic' is calculated using data from a sample. We're going to discuss how these statistics can be generalised to infer something about population parameters.

Let's start with a contrast. In regression analysis we take a sample and then analyse the relationship between two variables. This is very much focused upon the sample itself. However, in statistical analysis we want to go beyond talking about attributes of a single sample. We want to know about what those attributes say about the population from which the sample was drawn.

This jump from particular sample to general population is called statistical inference. But to make this jump we will use well known regularities found in the aggregate behaviour of many samples taken from a population. These patterns are known as sampling distributions.

The sampling distribution is a theoretical construct. Imagine taking a very large number of samples from a population, each of fixed size. These samples are called 'random samples' because every member of the population has an equal chance of being included in the sample. 

Now, every time a sample is taken, some statistic is measured - we will use the mean. Each of these means will usually differ as each sample is more or less different from the other. These differences are called sampling errors whereby the sample statistic deviates from the population parameter's value.

We record each of the means and plot them on a distribution known as the 'sampling distribution'. Do not confuse this with a 'sample distribution' which concerns the shape of the data within a single sample. The sampling distribution describes the shape of a statistic across many samples. It is this distribution that reveal an amazing hidden regularity that allows us to infer population parameters. This is captures in the 'central limit theorem'.

The central limit theorem says that if you take a large number of samples of fixed size then the distribution of the means will approach a normal distribution. The theorem has been shown to be true in a wide range of circumstances and is the central engine of statistical inference. It says that the mean of the sampling distribution approximates the mean of the population from which the samples were drawn. It also says that the standard deviation of the sampling distribution (of the sample means) is equal to the population standard deviation divided by the square root of the fixed sample size.






\end{document}
